{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMOgWvx1VgTw"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Enmi4dsZVolQ"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "import PIL.Image\n",
        "import PIL.ImageDraw\n",
        "import json\n",
        "from time import sleep\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace(\"•\", \"  *\")\n",
        "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CJ7onCOVtTv"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j33aKVQ1V5YN"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=\"AIzaSyCbiBH8z9Xvva2oLvdYFwgLdpfvIvou1bQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJfgnuYxVxPL"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0wAlDDj7U65"
      },
      "outputs": [],
      "source": [
        "from natsort import natsorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx3y6h0cGiFH"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat = model.start_chat(history=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5brkuujc2R7"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/ocr_results.quocngu.json\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "result = []\n",
        "\n",
        "idx = 1\n",
        "for x,y in data.items():\n",
        "    message ='''\n",
        "    Hãy sửa lỗi chính tả của văn bản tiếng việt sau\n",
        "    Chỉ trả về văn bản đã chỉnh sửa không cần giải thích gì thêm\n",
        "    Lấy đủ nội dung phiên âm và dịch nghĩa của bài thơ\n",
        "    '''\n",
        "    response = chat.send_message(\n",
        "      [\n",
        "          message,\n",
        "          y,\n",
        "      ],\n",
        "    )\n",
        "    print(response.text)\n",
        "    result.append({\"file_name\":x, \"text\": response.text})\n",
        "    with open(f\"/content/data/result{idx}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump({\"file_name\": x, \"text\": response.text}, f, ensure_ascii=False, indent=4)\n",
        "    idx += 1\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfXgjIpTF-_c"
      },
      "outputs": [],
      "source": [
        "with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
